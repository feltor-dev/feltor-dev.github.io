<!-- HTML header for doxygen 1.8.11-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<title>Discontinuous Galerkin Library: Introduction</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?.../MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="menubar.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
    <!--My own title area-->
  <ul class="menubar">
      <!-- <li><a href="../../../index.html">/</a><li>-->
    <li><a href="../../dg/html/modules.html">dG</a></li>
    <li><a href="../../geometries/html/modules.html">geometries</a></li>
    <li><a href="../../file/html/namespacefile.html">file</a></li>
    <li><a href="../../exblas/html/namespaceexblas.html">exblas</a></li>
  </ul>
  <!--End My own title area-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Discontinuous Galerkin Library
   </div>
   <div id="projectbrief">Discontinuous Galerkin numerical methods and container free numerical algorithms</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Introduction </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="pdf"></a>
Introduction to discontinuous Galerkin methods</h1>
<p>Here is a pdf document explainin the fundamentals of discontinuous Galerkin methods</p><ul>
<li><a href="./dg_introduction.pdf" target="_blank">Introduction to dg methods</a></li>
</ul>
<h1><a class="anchor" id="dispatch"></a>
The Level 1 dispatch system</h1>
<p>Let us first define some nomenclature to ease the following discussion</p><ul>
<li><em>Scalar:</em> A template parameter T is a Scalar if <code> typename dg::TensorTraits&lt;T&gt;::tensor_category </code> exists and derives from <code><a class="el" href="structdg_1_1_any_scalar_tag.html" title="Scalar Tag base class, indicates the basic Scalar Tensor concept. ">dg::AnyScalarTag</a></code> </li>
<li><em>Vector:</em> A template parameter T is a Vector if it is not a Scalar and if <code> typename dg::TensorTraits&lt;T&gt;::tensor_category </code> exists and derives from <code><a class="el" href="structdg_1_1_any_vector_tag.html" title="Vector Tag base class, indicates the basic Vector/container concept. ">dg::AnyVectorTag</a></code> </li>
<li><em>Matrix:</em> A template parameter T is a Matrix if it is not a Scalar or Vector and if <code> typename dg::TensorTraits&lt;T&gt;::tensor_category </code> exists and derives from <code><a class="el" href="structdg_1_1_any_matrix_tag.html">dg::AnyMatrixTag</a></code> </li>
<li><em>execution</em> <em>policy:</em> A template parameter T has an execution policy if <code> typename dg::TensorTraits&lt;T&gt;::execution_policy </code> exists and derives from <code><a class="el" href="structdg_1_1_any_policy_tag.html" title="Execution Policy base class. ">dg::AnyPolicyTag</a></code>, The execution policy is <em>trivial</em> if it is <code><a class="el" href="structdg_1_1_any_policy_tag.html" title="Execution Policy base class. ">dg::AnyPolicyTag</a></code> </li>
<li><em>value</em> <em>type</em> : A template parameter T has a value type if <code> typename dg::TensorTraits&lt;T&gt;::value_type </code> exists</li>
<li><em>compatible:</em> Two vectors are compatible if their tensor_categories both derive from the same base class that itself derives from but is not equal to <code><a class="el" href="structdg_1_1_any_vector_tag.html" title="Vector Tag base class, indicates the basic Vector/container concept. ">dg::AnyVectorTag</a></code>, Two execution policies are compatible if they are equal or if at least one of them is trivial.</li>
<li><em>promote:</em> A Scalar can be promoted to a Vector with all elements equal to the value of the Scalar. A Vector can be promoted to a Matrix with the Vector being the diagonal and all other elements zero.</li>
</ul>
<p>When dispatching level 1 functions we distinguish between three classes of functions: trivially parallel (<code><a class="el" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5" title="; Customizable and generic blas1 function ">dg::blas1::subroutine</a></code> and related <code><a class="el" href="namespacedg_1_1blas1.html" title="BLAS Level 1 routines. ">dg::blas1</a></code> functions), global communication (<code><a class="el" href="group__blas1.html#ga7b2aa636a0fe0c7d3298b9f869658919" title=" Binary reproducible Euclidean dot product between two vectors ">dg::blas1::dot</a></code> and <code><a class="el" href="group__blas2.html#gaaafba91956e948b0ea53f30889a3c20d" title="; Binary reproducible general dot product ">dg::blas2::dot</a></code>) and local communication (<code><a class="el" href="group__blas2.html#ga9bd2015d31362b25d61110f91cf3b0b9" title=" ">dg::blas2::symv</a></code>).</p>
<h2><a class="anchor" id="dispatch_subroutine"></a>
The subroutine function</h2>
<p>The execution of <code><a class="el" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5" title="; Customizable and generic blas1 function ">dg::blas1::subroutine</a></code> with a Functor called <code>routine</code> (and all related <code><a class="el" href="namespacedg_1_1blas1.html" title="BLAS Level 1 routines. ">dg::blas1</a></code> functions) is equivalent to the following:</p><ol type="1">
<li>Assert the following prerequisites:<ol type="a">
<li>All template parameter types must be either Scalars or Vectors and have an execution policy and a value type</li>
<li>All Vectors and all execution policies must be mutually compatible</li>
<li>All Vectors must contain the same number of elements (equal sizes)</li>
<li>The number of template parameters must be equal to the number of parameters in the <code>routine</code> </li>
<li>The value type of every template parameter must be convertible to the respective parameter type in the <code>routine</code> </li>
</ol>
</li>
<li>If all types are Scalars, apply the <code>routine</code> and return</li>
<li>If at least one type is a Vector, then all Scalars are promoted to this type with the same size, communicator and execution policy</li>
<li>Check the base class of the tensor_category:<ol type="a">
<li>If <code><a class="el" href="structdg_1_1_shared_vector_tag.html" title="Indicate a contiguous chunk of shared memory. ">dg::SharedVectorTag</a></code>, check execution policy and dispatch to respective implementation (The implementation just loops over all elements in the vectors and applies the <code>routine</code>)</li>
<li>If <code><a class="el" href="structdg_1_1_m_p_i_vector_tag.html" title="A distributed vector contains a data container and a MPI communicator. ">dg::MPIVectorTag</a></code>, access the underlying data and recursively call <code><a class="el" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5" title="; Customizable and generic blas1 function ">dg::blas1::subroutine</a></code> (and start again at 1)</li>
<li>If <code><a class="el" href="structdg_1_1_recursive_vector_tag.html" title="This tag indicates composition/recursion. ">dg::RecursiveVectorTag</a></code>, loop over all elements and recursively call <code><a class="el" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5" title="; Customizable and generic blas1 function ">dg::blas1::subroutine</a></code> for all elements (and start again at 1)</li>
</ol>
</li>
</ol>
<h2><a class="anchor" id="dispatch_dot"></a>
The dot function</h2>
<p>The execution of <code><a class="el" href="group__blas1.html#ga7b2aa636a0fe0c7d3298b9f869658919" title=" Binary reproducible Euclidean dot product between two vectors ">dg::blas1::dot</a></code> and <code><a class="el" href="group__blas2.html#gaaafba91956e948b0ea53f30889a3c20d" title="; Binary reproducible general dot product ">dg::blas2::dot</a></code> is equivalent to the following:</p><ol type="1">
<li>Assert the following prerequisites:<ol type="a">
<li>All template parameter types must be either Scalars or Vectors and have an execution policy and a value type</li>
<li>All Vectors and all execution policies must be mutually compatible</li>
<li>All Vectors must contain the same number of elements (equal sizes)</li>
</ol>
</li>
<li>If all types are Scalars, multiply and return</li>
<li>If at least one type is a Vector, then all Scalars are promoted to this type with the same size, communicator and execution policy</li>
<li>Check the base class of the tensor_category:<ol type="a">
<li>If <code><a class="el" href="structdg_1_1_shared_vector_tag.html" title="Indicate a contiguous chunk of shared memory. ">dg::SharedVectorTag</a></code>, check execution policy and dispatch to respective implementation (The implementation multiplies and accumulates all elements in the vectors). Return the result.</li>
<li>If <code><a class="el" href="structdg_1_1_m_p_i_vector_tag.html" title="A distributed vector contains a data container and a MPI communicator. ">dg::MPIVectorTag</a></code>, assert that the vector MPI-communicators are <code>congruent</code> or <code>ident</code>. Then, access the underlying data and recursively call <code>dot</code> (and start again at 1). Accumulate the result among participating processes and return.</li>
<li>If <code><a class="el" href="structdg_1_1_recursive_vector_tag.html" title="This tag indicates composition/recursion. ">dg::RecursiveVectorTag</a></code>, loop over all elements and recursively call <code>dot</code> for all elements (and start again at 1). Accumulate the results and return.</li>
</ol>
</li>
</ol>
<h2><a class="anchor" id="dispatch_symv"></a>
The symv function</h2>
<p>The execution of the <code><a class="el" href="group__blas2.html#ga9bd2015d31362b25d61110f91cf3b0b9" title=" ">dg::blas2::symv</a></code> (and <code><a class="el" href="group__blas2.html#ga1b7e3b58697b6e93169eebbda63f3ed3" title="; (alias for symv) ">dg::blas2::gemv</a></code>) functions is hard to discribe in general since each matrix class has individual prerequisites and execution paths. Still, we can identify some general rules:</p><ol type="1">
<li>The Matrix type can be either a Scalar (promotes to Scalar times the Unit Matrix), a Vector (promotes to a diagonal Matrix) or a Matrix</li>
<li>If the Matrix is either a Scalar or a Vector and the remaining types do not have the <code><a class="el" href="structdg_1_1_recursive_vector_tag.html" title="This tag indicates composition/recursion. ">dg::RecursiveVectorTag</a></code> tensor category, then <code><a class="el" href="group__blas2.html#ga9bd2015d31362b25d61110f91cf3b0b9" title=" ">dg::blas2::symv</a></code> is equivalent to <code><a class="el" href="group__blas1.html#gad2dcd7cffe760b7bacfdd7647d86e602" title=" ">dg::blas1::pointwiseDot</a></code> </li>
<li>If the Matrix has the <code><a class="el" href="structdg_1_1_self_made_matrix_tag.html" title="Indicates that the type has a member function with the same name and interface (up to the matrix itse...">dg::SelfMadeMatrixTag</a></code> tensor category, then all parameters are immediately forwarded to the <code>symv</code> member function. No asserts are performed and none of the following applies.</li>
<li>The container template parameters must be Vectors or Scalars and must have compatible execution policies. Vectors must be compatible.</li>
<li>If the tensor category of the Vectors is <code><a class="el" href="structdg_1_1_recursive_vector_tag.html" title="This tag indicates composition/recursion. ">dg::RecursiveVectorTag</a></code> and the tensor category of the Matrix is not, then the <code><a class="el" href="group__blas2.html#ga9bd2015d31362b25d61110f91cf3b0b9" title=" ">dg::blas2::symv</a></code> is recursively called with the Matrix on all elements of the Vectors.</li>
</ol>
<h2><a class="anchor" id="dispatch_examples"></a>
Examples</h2>
<p>Let us assume that we have two vectors \( v\) and \( w\). In a shared memory code these will be declared as </p><div class="fragment"><div class="line"><a class="code" href="group__typedefs.html#ga5bbe4ba51ef8ff8d506979d0beda25b8">dg::DVec</a> v, w;</div><div class="line"><span class="comment">// initialize v and w with some meaningful values</span></div></div><!-- fragment --><p> In an MPI implementation we would simply write <code><a class="el" href="group__typedefs.html#ga1e23fb8b50d38d43beb4bf3689c20a55" title="MPI Device Vector s.a. dg::DVec. ">dg::MDVec</a></code> instead of <code><a class="el" href="group__typedefs.html#ga5bbe4ba51ef8ff8d506979d0beda25b8" title="Device Vector. The device can be an OpenMP parallelized cpu or a gpu. This depends on the value of th...">dg::DVec</a></code>. Let us now assume that we want to compute the expression \( v_i \leftarrow v_i^2 + w_i\) with the <a class="el" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5" title="; Customizable and generic blas1 function ">dg::blas1::subroutine</a>. The first step is to write a Functor that implements this expression </p><div class="fragment"><div class="line"><span class="keyword">struct </span>Expression{</div><div class="line">   <a class="code" href="functions_8h.html#aa181978ebbc17b8ea6d6c072e06c2d05">DG_DEVICE</a></div><div class="line">   <span class="keywordtype">void</span> operator() ( <span class="keywordtype">double</span>&amp; v, <span class="keywordtype">double</span> w){</div><div class="line">      v = v*v + w;</div><div class="line">   }</div><div class="line">};</div></div><!-- fragment --><p> Note that we used the Marco <a class="el" href="functions_8h.html#aa181978ebbc17b8ea6d6c072e06c2d05">DG_DEVICE</a> to enable this code on GPUs. The next step is just to apply our struct to the vectors we have. </p><div class="fragment"><div class="line"><a class="code" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5">dg::blas1::subroutine</a>( Expression(), v, w);</div></div><!-- fragment --><p>Now, we want to use an additional parameter in our expresion. Let's assume we have </p><div class="fragment"><div class="line"><span class="keywordtype">double</span> parameter = 3.;</div></div><!-- fragment --><p> and we want to compute \( v_i \leftarrow p v_i^2 + w_i\). We now have two possibilities. We can add a private variable in <code>Expression</code> and use it in the implementation of the paranthesis operator </p><div class="fragment"><div class="line"><span class="keyword">struct </span>Expression{</div><div class="line">   Expression( <span class="keywordtype">double</span> param):m_param(param){}</div><div class="line">   <a class="code" href="functions_8h.html#aa181978ebbc17b8ea6d6c072e06c2d05">DG_DEVICE</a></div><div class="line">   <span class="keywordtype">void</span> operator() ( <span class="keywordtype">double</span>&amp; v, <span class="keywordtype">double</span> w)<span class="keyword">const</span>{</div><div class="line">       v = m_param*v*v + w;</div><div class="line">   }</div><div class="line">   <span class="keyword">private</span>:</div><div class="line">   <span class="keywordtype">double</span> m_param;</div><div class="line">};</div><div class="line"><a class="code" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5">dg::blas1::subroutine</a>( Expression(parameter), v, w);</div></div><!-- fragment --><p> The other possibility is to extend the paranthesis operator in <code>Expression</code> and call <code><a class="el" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5" title="; Customizable and generic blas1 function ">dg::blas1::subroutine</a></code> with a scalar </p><div class="fragment"><div class="line"><span class="keyword">struct </span>Expression{</div><div class="line">   <a class="code" href="functions_8h.html#aa181978ebbc17b8ea6d6c072e06c2d05">DG_DEVICE</a></div><div class="line">   <span class="keywordtype">void</span> operator() ( <span class="keywordtype">double</span>&amp; v, <span class="keywordtype">double</span> w, <span class="keywordtype">double</span> param){</div><div class="line">       v = param*v*v + w;</div><div class="line">   }</div><div class="line">};</div><div class="line"><a class="code" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5">dg::blas1::subroutine</a>( Expression(), v, w, parameter);</div></div><!-- fragment --><p> The result (and runtime) is the same in both cases. However, the second is more versatile, when we use recursion. Consider that \( v,\ w\) and \( p\) are now arrays, declared as </p><div class="fragment"><div class="line">std::array&lt;dg::DVec, 3&gt; array_v, array_w;</div><div class="line">std::array&lt;double,3&gt; array_parameter;</div><div class="line"><span class="comment">// initialize array_v, array_w and array_parameter meaningfully</span></div></div><!-- fragment --><p> We now want to compute the expression \( v_{ij} \leftarrow p_i v_{ij}^2 + w_{ij}\), where <code>i</code> runs from 0 to 2 and <code>j</code> runs over all elements in the shared vectors <code> array_v[i] </code> and <code> array_w[i] </code>. In this case we just call </p><div class="fragment"><div class="line"><a class="code" href="group__blas1.html#ga7386b5cb0144d5364b8ea8c8ce1482a5">dg::blas1::subroutine</a>( Expression(), array_v, array_w, array_parameter);</div></div><!-- fragment --><p> and use the fact that <code> std::array </code> has the <code><a class="el" href="structdg_1_1_recursive_vector_tag.html" title="This tag indicates composition/recursion. ">dg::RecursiveVectorTag</a></code>.</p>
<p>In order to compute the sum \( \sum_{i=0}^2 p_i\) we can use </p><div class="fragment"><div class="line"><span class="keywordtype">double</span> sum = <a class="code" href="group__blas1.html#ga7b2aa636a0fe0c7d3298b9f869658919">dg::blas1::dot</a>( 1, array_parameter);</div></div><!-- fragment --><h1><a class="anchor" id="mpi_backend"></a>
The MPI interface</h1>
<dl class="section note"><dt>Note</dt><dd>The mpi backend is activated by including <code>mpi.h</code> before any other feltor header file </dd></dl>
<h2><a class="anchor" id="mpi_vector"></a>
MPI Vectors and the blas1 functions</h2>
<p>In Feltor each mpi process gets an equally sized chunk of a vector. The corresponding structure in FELTOR is the <code><a class="el" href="structdg_1_1_m_p_i___vector.html" title="mpi Vector class ">dg::MPI_Vector</a></code>, which is nothing but a wrapper around any container type object and a <code>MPI_Comm</code>. With this the <code><a class="el" href="namespacedg_1_1blas1.html" title="BLAS Level 1 routines. ">dg::blas1</a></code> functions can readily be implemented by just redirecting to the implementation for the container type. The only functions that need communication are the <code><a class="el" href="group__blas1.html#ga7b2aa636a0fe0c7d3298b9f869658919" title=" Binary reproducible Euclidean dot product between two vectors ">dg::blas1::dot</a></code> functions (<code>MPI_Allreduce</code>).</p>
<h2><a class="anchor" id="mpi_matrix"></a>
Row and column distributed matrices</h2>
<p>Contrary to a vector a matrix can be distributed among processes in two ways: <em>row-distributed</em> and <em>column-distributed</em>. In a row-distributed matrix each process gets the rows of the matrix that correspond to the indices in the vector it holds. In a column-distributed matrix each process gets the columns of the matrix that correspond to the indices in the vector it holds. When we implement a matrix-vector multiplication the order of communication and computation depends on the distribution of the matrix. First, we define the structure <code><a class="el" href="structdg_1_1_m_p_i_dist_mat.html" title="Distributed memory matrix class. ">dg::MPIDistMat</a></code> as a simple a wrapper around a LocalMatrix type object and an instance of a <code><a class="el" href="structdg_1_1a_communicator.html" title="Struct that performs collective scatter and gather operations across processes on distributed vectors...">dg::aCommunicator</a></code>. </p>
<h3><a class="anchor" id="row"></a>
Row distributed</h3>
<p>For the row-distributed matrix each process first has to gather all elements of the input vector it needs to be able to compute the elements of the output. In general this requires MPI communication. (read the documentation of <code><a class="el" href="structdg_1_1a_communicator.html" title="Struct that performs collective scatter and gather operations across processes on distributed vectors...">dg::aCommunicator</a></code> for more info of how global scatter/gather operations work). Formally, the gather operation can be written as a matrix \(G\) of \(1&#39;\)s and \(0&#39;\)s. After the elements have been gathered into a buffer the local matrix-vector multiplications can be executed. </p><p class="formulaDsp">
\[ M = R\cdot G \]
</p>
<p> where \(R\) is the row-distributed matrix with modified indices and \(G\) is the gather matrix, in which the MPI-communication takes place. The <code><a class="el" href="structdg_1_1_row_col_dist_mat.html" title="Distributed memory matrix class, asynchronous communication. ">dg::RowColDistMat</a></code> goes one step further and separates the matrix \( R\) into a part that can be computed entirely on the local process and a part that needs communication.</p>
<h3><a class="anchor" id="column"></a>
Column distributed</h3>
<p>In a column distributed matrix the local matrix-vector multiplication can be executed first because each processor already has all vector elements it needs. However the resuling elements have to be communicated back to the process they belong to. Furthermore, a process has to sum all elements it receives from other processes on the same index. This is a scatter and reduce operation and it can be written as a scatter matrix \(S\) (s.a. <code><a class="el" href="structdg_1_1a_communicator.html" title="Struct that performs collective scatter and gather operations across processes on distributed vectors...">dg::aCommunicator</a></code>). The transpose of the scatter matrix is a gather matrix and vice-versa. </p><p class="formulaDsp">
\[ M = S\cdot C \]
</p>
<p> where \(S\) is the scatter matrix and \(C\) is the column distributed matrix with modified indices.</p>
<p>It turns out that a row-distributed matrix can be transposed by transposition of the local matrices and the gather matrix (s.a. <code><a class="el" href="group__lowlevel.html#gaccb5652aaa2d450d97996d4eee6de546" title="Generic matrix transpose method. ">dg::transpose</a></code>). The result is then a column distributed matrix. The transpose of a column distributed matrix is a row-distributed matrix and vice-versa. You can create an MPI row-distributed matrix if you know the global column indices by our <code><a class="el" href="group__mpi__structures.html#gaf94a6a2fb51d6f795e0e9c81ae03fcdb" title="Convert a matrix with local row and global column indices to a row distributed MPI matrix...">dg::convert</a></code> function. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Tue Aug 28 2018 23:02:50 for Discontinuous Galerkin Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
