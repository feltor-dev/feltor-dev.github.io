%%%%%%%%%%%%%%%%%%%%%definitions%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{../header.tex}
\input{../newcommands.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%DOCUMENT%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
%\preprint{}

\title{The parallel derivative on structured grids}
\author{M.~Wiesenberger}
%\email{Matthias.Wiesenberger@uibk.ac.at}
%\ead{Matthias.Wiesenberger@uibk.ac.at}
%\affiliation{Institute for Ion Physics and Applied Physics, Association EURATOM-\"OAW,  University of
%   Innsbruck, A-6020 Innsbruck, Austria}
%\author{M.~Held}
%\affiliation{Institute for Ion Physics and Applied Physics, Association EURATOM-\"OAW,  University of
   %Innsbruck, A-6020 Innsbruck, Austria}
%\address{Institute for Ion Physics and Applied Physics, Association EURATOM-\"OAW,  Universit\"at 
%   Innsbruck, A-6020 Innsbruck, Austria}
 
\maketitle
\section{Semi-Lagrangian schemes} \label{sec:parallel}
In this section we show how to numerically treat parallel derivatives in a non field
aligned coordinate system.
We introduce the method in Section~\ref{sec:parallela} %.In Section~\ref{sec:parallelb} we
and discuss some problems arising from the boundaries of the computational domain.
Finally, we propose a field line mapping for variable initialization in Section~\ref{sec:parallelc}.

\subsection{Discretization of parallel derivatives} \label{sec:parallela}
Given is a vector field $\vec v(R,Z)$ in cylindrical coordinates $R,Z,\varphi$ independent of $\varphi$ and we want to 
discretize the derivative $\vec v \cdot\nabla f \equiv \nabla_\parallel f$. 
This $\vec v$ might be the magnetic unit vector field but the algorithm works 
for any vector field $\vec v$ with $v^\varphi\neq 0$, in especially $\vec v$ does not need
to have unit length.

We begin with the formulation of a field-aligned discretization. If $s$ denotes the 
field line following coordinate, then the one-dimensional discrete derivative along the field line reads
\begin{align}
    \frac{\d f }{\d s} \rightarrow \frac{f_{k+1}-f_{k-1}}{s_{k+1} - s_{k-1}}.
    \label{eq:proposition}
\end{align}
Note here that $s$ does NOT denote the distance 
(especially since we do not require the existence of a metric at this point).

To every smooth vector field $\vec v(\vec x)$ there is a unique curve of which the
tangent in a point $p$ is the value of $\vec v(p)$ at that point. It is given by
the solution of the differential equation
\begin{align}
    \frac{\d z^i}{\d s} = v^i(\vec z)
    \label{eq:integralcurve}
\end{align}
where $z^i$ is one of $(R, Z, \varphi)$ and $v^i$ are the contravariant components
of $\vec v$ in cylindrical coordinates. 
Moreover, by definition we have
\begin{align}
    \frac{\d f(\vec z(s))}{\d s} = \vec v\cdot \nabla f|_{\vec z(s)}
    \label{}
\end{align}
along a field line parameterized by $s$, 
i.e. instead of $\nabla_\parallel f$ we can choose to discretize $\frac{\d f}{\d s}$.

Let us divide the $\varphi$ direction into $N_\varphi$ equidistant planes of 
$\Delta \varphi$. Unfortunately, from Eq.~\eqref{eq:integralcurve} we cannot easily determine
$\Delta s$ for given $\Delta \varphi$. It is better to use the transformation $\d t = v^\varphi \d s$
\begin{align}
    \frac{\d z^i}{\d t} = \frac{v^i}{v^\varphi}
    \label{}
\end{align}
since in this case $\d\varphi/\d t = 1 \Rightarrow t=\varphi$. We get
\begin{subequations}
\begin{align}
    \frac{\d R}{\d\varphi}&= \frac{v^R}{v^\varphi},\\ %\frac{R}{I}\frac{\partial\psi}{\partial Z},\\
    \frac{\d Z}{\d\varphi}&=\frac{v^Z}{v^\varphi},%-\frac{R}{I}\frac{\partial\psi}{\partial R}.
\end{align}
\text{ together with the equation  }
\begin{align}
    \frac{\d s}{\d\varphi} &= \frac{1}{|v^\varphi|} %= \frac{B}{|B^\varphi|}% = \frac{R_0R^2B}{I}=R_0R\sqrt{1+\frac{|\nabla\psi|^2}{I^2}}
    \label{eq:fieldlinec}
\end{align}
\label{eq:fieldline}
\end{subequations}
for $s$. 
Eqs.~\eqref{eq:fieldline} are integrated from $\varphi=0$ to $\varphi=\pm \Delta \varphi$. 
We characterize the flow generated by $\vec v/v^\varphi$ by
\begin{align}
    \Tpm\vec z := \Tpm[R, Z, \varphi]:= ( R(\pm \Delta\varphi), Z( \pm \Delta\varphi), \varphi\pm\Delta \varphi),
    \label{}
\end{align}
where $(R(\varphi), Z(\varphi), s(\varphi))$ is the solution to Eqs.~\eqref{eq:fieldline} 
with initial condition 
\begin{align}
    (R(0), Z(0), s(0)) = (R, Z, 0).
    \label{}
\end{align} 
Obviously we have $\Tm\circ\Tp = \Eins$, but $\Tpm$ is not unitary since $\vec v/v^\varphi$ is 
not divergence free. 

The proposed centered discretization~\eqref{eq:proposition} for the parallel derivative then reads
\begin{align}
    \nabla_\parallel f \equiv \frac{df}{ds} = \frac{df}{d\varphi}\frac{d\varphi}{ds} 
    \rightarrow \frac{f\left(T_{\Delta\varphi}^+\vec z\right)-f\left(T_{\Delta\varphi}^-\vec z\right)}{s(+\Delta\varphi) - s(-\Delta\varphi)},
    \label{eq:paralleldis}
\end{align}
which is slightly different from Reference~\cite{Hariri2014}, where
the relation~\eqref{eq:fieldlinec} was used to replace $\d \varphi/\d s$. 
Since the $R$ and $Z$ coordinates are still discretized in the dG framework we note that in our work
the interpolation of $f$ on the transformed points $\Tpm\vec z$
is naturally given by interpolating the base polynomials. 
Let us for a moment omit the $Z$ coordinate for ease of notation. 
If $(R_{nj}, \varphi_k)$ are the grid points, 
we call $(R^+_{nj}, \varphi_{k+1}) := \Tp[R_{nj}, \varphi_k]$ and 
$(R_{nj}^-, \varphi_{k-1}) := \Tm[R_{nj}, \varphi_k]$ the transformed coordinates along
the field lines. We then have
\begin{subequations}
\begin{align}
    f(\Tp\vec z) = f( R^+_{nj}, \varphi_{k+1}) = \bar f_{k+1}^{ml}p_{ml}(R^+_{nj}) =: (I^+)_{nj}^{ml}f_{(k+1)ml} , \\
    f(\Tm\vec z) = f( R^-_{nj}, \varphi_{k-1}) = \bar f_{k-1}^{ml}p_{ml}(R^-_{nj}) =: (I^-)_{nj}^{ml}f_{(k-1)ml} , 
\end{align}
\label{eq:interpolation}
\end{subequations}
where the backward transformations of $\bar{ \vec f}$ are hidden in $I$.
Thus the interpolation of all the necessary points can simply be written as a matrix-vector product, where the interpolation matrices $I^+$  and $I^-$ are independent of time since
the field lines are constant in time. The order of this interpolation is given by $P$, the number of polynomial coefficients.
A consistency check is the relation $I^+\circ I^- = \Eins$. 

The discretization~\eqref{eq:paralleldis} can now be written as a matrix vector product
\begin{align}
    \nabla_\parallel f \rightarrow S \circ \left[ \Eins^+\otimes I^+ - \Eins^- \otimes I^-  \right] \vec f, 
    \label{}
\end{align}
where $S$ is the diagonal matrix that contains the entries $1/(s(+\Delta\varphi) - s(-\Delta\varphi))$.
This discretization is not skew-symmetric since the
field lines are not volume-preserving, or~$(I^+)^\mathrm{T} \neq I^-$.
In fact, the adjoint of the parallel derivative is
\begin{align}
    \nabla_\parallel^\dagger f = - \nabla\cdot(\vec v\ f ) \neq -\nabla_\parallel f.
    \label{}
\end{align}
Note that with this relation we can define the parallel 
diffusion operator as
\begin{align}
    \Delta_\parallel := -\nabla_\parallel^\dagger \nabla_\parallel = (\nabla\cdot \vec{ \hat v}) \nabla_\parallel + \nabla_\parallel^2 , 
    \label{}
\end{align}
which is indeed the parallel part of the full Laplacian $\Delta = \nabla\cdot( \vec{ \hat v} \nabla_\parallel + \nabla_\perp)$.
$\vec{ \hat v} $ is the unit vector $\vec v/ |\vec v|$.
The second order derivative $\nabla_\parallel^2$ can be 
discretized using 
\begin{align}
    \frac{\d^2 f}{\d s^2} \rightarrow  
    \frac{2f_{k+1} }{(s_{k+1}-s_k)(s_{k+1}-s_{k-1})} -
    \frac{2f_k}{(s_{k+1}-s_k)(s_k - s_{k-1})} \nonumber\\ + 
    \frac{2f_{k-1} }{(s_{k}-s_{k-1})(s_{k+1}-s_{k-1})} 
    \label{}
\end{align}
and repeating the procedure of this section.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Change of coordinates}
In principle the above considerations hold in any
coordinate system $\eta,\zeta,\varphi$, since the directional derivative is 
an intrinsic operation.
The only question is how to integrate the field lines in the 
$\eta, \zeta,\varphi$ system 
since we assumed that our vector field $\vec v(\vec x)$ was given 
analytically in 
cylindrical coordinates. There are two possibilities. 
First, interpolate $R(\zeta_i, \eta_i), Z(\zeta_i, \eta_i)$ for 
all $i$, then integrate $\vec v$ in $(R,Z)$ space and finally use
Newton iteration to find $\zeta(R^\pm_i, Z^\pm_i), \eta(R^\pm_i, Z^\pm_i)$. 
The downside here is that it is difficult to tell when and where the fieldline leaves the simulation domain.

The second possibiliy (the one currently implemented) 
is to integrate entirely in the 
transformed coordinate system $\zeta, \eta, \varphi$. 
The magnetic field can be easily transformed since we have the
Jacobian of the coordinate transformation
\begin{align}
    v^\zeta(\zeta, \eta) &= \left(\frac{\partial \zeta}{\partial R} v^{R} + \frac{\partial \zeta}{\partial Z}v^Z\right)_{R(\zeta, \eta), Z(\zeta, \eta)} \\
    v^\eta(\zeta, \eta) &= \left(\frac{\partial \eta}{\partial R} v^{R} + \frac{\partial \eta}{\partial Z}v^Z\right)_{R(\zeta, \eta), Z(\zeta, \eta)} \\
    v^\varphi(\zeta, \eta) &= v^\varphi({R(\zeta, \eta), Z(\zeta, \eta)})
    \label{eq:field_trafo}
\end{align}
The fieldline equations~\eqref{eq:fieldline} are still
\begin{subequations}
\begin{align}
\frac{\d \zeta}{\d\varphi} &= \frac{v^\zeta}{v^\varphi}\\
\frac{\d \eta}{\d\varphi} &= \frac{v^\eta}{v^\varphi}\\
\frac{\d s}{\d\varphi} &= \frac{1}{|v^\varphi|}
\end{align}
\label{eq:fieldlines}
\end{subequations}
The issue here is that when integrating fieldlines we
have to interpolate the vector field $\vec v$ at arbitrary points. 
However, the interpolation error vanishes with order $P$ in the 
perpendicular plane. In order to mitigate this error
we transform $\vec v$ on a finer grid/higher order polynomials for more accurate
integration.
Apart from the issue of how to get the transformed vector field 
the remaining algorithm for $\vec v\cdot\nabla$ is entirely unchanged.

\subsection{Boundary conditions}
The question is what to do when a fieldline intersects with the boundary
of the simulation domain before reaching the next plane.
Boundary conditions are formulated by either setting a value 
on the boundary of the domain (Dirichlet) or by fixing 
the derivative perpendicularly to the boundary (Neumann), or 
a combination of both ( Robin). 

The problem with a Dirichlet boundary condition 
is that we need to find the exact place where the fieldline 
reaches the boundary. 
We have to find
$\varphi_b$ such that the result of the integration of Eq.~\eqref{eq:fieldline} from 
$0$ to $\varphi_b$ lies on the boundary. 
The angle $\varphi_b$ can be found by a bisection algorithm knowing that $0<\varphi_b < \Delta\varphi$. 
This kind of procedure is known as a shooting method. 
Secondly, for Dirichlet boundaries the small 
distance of a point to the wall seriously deteriorates the CFL condition. (To ease the CFL condition 
was the reason to devise the algorithm in the first place)

The problem with Neumann boundaries is that they are usually given 
perpendicularly to the boundary and that the fieldlines are not necessarily
perpendicular to the boundary. 

\subsection{Avoiding boundary conditions}
An obvious way to avoid boundary conditions is to
align the simulation domain to the vector field such that the fieldlines
never intersect the boundary. This is possible in FELTOR (read the
geometry section).

When computing in non-aligned coordinate systems
one idea to avoid boundary conditions 
is to simply cut the contribution from field lines
that leave the computational domain. While this works in practice
it is unclear what numerical and physical side-effects this procedure might have. 

Another solution would be to change the 
vector field $\vec v$ and only retain the toroidal part of $\vec v$ on the 
boundary ( $v^R|_{\partial\Omega} = v^Z|_{\partial\Omega} =0$). The fieldlines then have a kink on the boundary $\partial\Omega$. 
On the other hand we can implement boundary conditions consistent with 
the perpendicular ones since the fieldlines never leave the domain. 
We simply interpolate the quantity to derive on the inner side of the
domain boundary (Neumann conditions = "No boundary condition") or 
set the value to zero (Dirichlet condition).

\subsection{Poloidal limiters}
A poloidal limiter can simply be implemented via a boundary condition in $\varphi$. 
As long as the form of the limiter is aligned with a flux-function we do not have to 
integrate a field line in order to determine which points lie in the
limiter-shadow. It is therefore straightforward to implement ghost-cells 
in that case. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The adjoint methods}
The idea is to discretize the operation $\nabla\cdot( \vec v .)$ by
taking the adjoint of the discretization for $\nabla_\parallel$. 
In order to understand what the adjoint operators do let us denote $\Tp$ as the push-forwward operator. Then we have
\begin{align}
    \int f(\vec x) \Tp h(\vec x) \sqrt{g(\vec x)}\d^3x% \\
    %=  \int f(\vec x) h(\Tm \vec x)\sqrt{g(\vec x)}\d^3x \\
    %=  \int f(\Tp \vec x') h(\vec x')\sqrt{g(\Tp \vec x')}J^{-1}( \Tp\vec x') \d^3x' \\
    =  \int \frac{1}{\sqrt{g(\vec x')}}\Tm\left[J^{-1}(\vec x')\sqrt{g(\vec x')}f(\vec x')\right] h(\vec x')\sqrt{g(\vec x')}   \d^3x' \\
    \equiv  \int (\Tp)^\dagger\left[f(\vec x)\right] h(\vec x)\sqrt{g(\vec x)}   \d^3x
    \label{}
\end{align}
$J$ is the determinant of the Jacobian $\partial(\vec x')/\partial(\vec x)$ with $\vec x' = \Tm \vec x$.
In the last step we simply replaced the dummy variable $\vec x'$ with $\vec x$ again and identified the relevant terms
as the adjoint operator:
\begin{align}
    (\Tp)^\dagger f(\vec x ) := \frac{1}{\sqrt{g(\vec x)}} \Tm\left[\sqrt{g(\vec x)} J^{-1}(\vec x) f(\vec x) \right]
    \label{}
\end{align}
This means that numerically the adjoint of the push-forward 
operator should be a valid discretization of its inverse.
Note that $\sqrt{g}J^{-1}(\vec x) = \sqrt{g'(\Tm \vec x)}$.
With this we can write
\begin{align}
    (\Tp)^\dagger f(\vec x ) := \sqrt{\frac{g'(\vec x)}{g(\vec x)}} \Tm\left[f(\vec x) \right]
    \label{}
\end{align}
Also note that $\Tp [fh] = \Tp f \Tp h$ might not 
hold on the discrete level. Also the question is how $J$ enters 
on the discrete level. We have to multiply $\sqrt{g}$ artificially when we form the adjoint. 
Theoretically $J$ could be hidden somehow when we integrate the fieldlines, so the information could be contained in the discrete version? (Maybe in the back-projection?)

If the streamlines are divergence free, we have $J=1$.
A numerical test could be ( if we neglect the volume form in the adjoint)
\begin{align}
    (\Tp)^\dagger \left[J(\vec x)\Tp f(\vec x)\right] - f(\vec x) = 0
    \label{}
\end{align}
The numerical computation of $J$ might a bit tricky at the boundaries. 
In a flux-aligned $\zeta, \eta$ it should be feasible but in cylindrical coordinates I don't know how. Maybe we can simply cut the last few cells before the boundary.
Even easier might be
\begin{align}
    \left(\Tp\right)^\dagger J(\vec x ) = 1
    \label{}
\end{align}

If we integrate streamlines of the vector field $\vec B/B^\varphi$, then we have
\begin{align}
    \frac{\d J}{\d \varphi} = J(\vec x ) \nabla\cdot\left( \vec B/B^\varphi\right)
    \label{}
\end{align}
along these streamlines.
Also we have that $\d s = B/B^\varphi \d \varphi $ and the interpolation/projection of $\triangle s$ can probably be neglected. (We want to neglect it because it's memory intensive to store all combinations)
Also this means that when we transpose $\nabla_\parallel$ we get a 
multiplication by $B^\varphi/B$ in the beginning.
In any case this means that we want to have 
\begin{align}
\left(\Tp\right)^\dagger B^\varphi  =  B^\varphi
\end{align}


\subsection{A grid refinement approach}
While the idea of the last section sounds appealing the problem 
is that the discretization does not converge.
The idea of the sandwich method \cite{Stegmeir2016} is 
to bracket the parallel derivative by interpolation and 
projection matrices:
\begin{align}
    \nabla^c_\parallel &= P\nabla_\parallel^f Q \\
    \nabla^{c\dagger}_\parallel &= P \nabla^{f\dagger}_\parallel Q
    \label{eq:sandwich}
\end{align}
In this way the projection integrals
\begin{align}
    \int\dV (\nabla_\parallel f) p_i(x)p_j(y) 
    \label{}
\end{align}
are computed more precisely.
The size of the fine grid should therefore be as large as
possible.
We first notice that the one interpolation matrix can be absorbed
in the parallel derivative since this also consists of 
interpolation operations. 
\begin{align}
    \nabla^c_\parallel &= P\nabla_\parallel^{fc} \\
    \nabla^{c\dagger}_\parallel &= \nabla^{fc\dagger}_\parallel Q
    \label{eq:sandwich}
\end{align}
Note that the matrix-matrix multiplications in Eq.~\eqref{eq:sandwich} can
be precomputed and stored. The memory requirements 
in the final computations are 
therefore the same  as in the old version. (Not entirely, since
the diagonal $1/\Delta s$ matrix does not commute with $Q$ or $P$).

Finally remember that the adjoint of a matrix in the modified geometry 
involves the volume element. This means that after you've adjoined the 
parallel derivative the normal way simply bracket the result 
by $1/\sqrt{g}$ and $\sqrt{g}$. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithm}
Given are the components $v^i(R,Z)$ for $i\in\{R,Z,\varphi\}$ and a compuational grid (in the following the ``coarse grid``)
\begin{itemize}
  \item generate a fine grid by multiplying the cell numbers of the given coarse grid (only topologcially, metric and Jacobian are not needed)
  \item integrate the fieldlines for the fine grid:
    \begin{itemize}
      \item evaluate the starting points on the coarse grid in computational space 
      \item For a curvilinear grid set up a (higher order) grid for the 
        interpolation of the vector components $v^i$ and push forward the vector components
        to the curvilinear coordinate system
      \item Integrate the fieldline equations 
\begin{subequations}
\begin{align}
\frac{\d \zeta}{\d\varphi} &= \frac{v^\zeta}{v^\varphi}\\
\frac{\d \eta}{\d\varphi} &= \frac{v^\eta}{v^\varphi}\\
\frac{\d s}{\d\varphi} &= \frac{1}{|v^\varphi|}
\end{align}
\label{eq:fieldlines_converted}
\end{subequations}
    with the given starting points and $s(0)=0$ from $\varphi=0$ until $\varphi = \pm\Delta \varphi$.
      \item create an interpolation matrix that interpolates from the coarse grid 
        to the fine grid
      \item use the interpolation matrix to generate the plus/minus points for the fine grid
    \end{itemize}
  \item create the interpolation matrices that interpolate from the given coarse grid 
    to the plus/minus points 
  \item create a projection matrix that projects from the fine grid to the coarse grid
  \item compute the matrix-matrix multiplications $P\cdot I^\pm$ as well as the transpose
  \item project the $s$ vectors to the coarse grid
\end{itemize}

\subsection{Notes on the MPI implmentation}
We note that we normally construct $\nabla_\parallel^{fc}$ as a column 
distributed
matrix. The advantage is then that the gather operation is bijective, i.e. the transpose of the gather matrix is its inverse. 
This advantage is lost in the present problem. 
It turns out that it is advantageous to construct $\nabla_\parallel^{fc}$
as s row-distributed matrix with global indices. 
This is because a column distributed matrix can be easily (without mpi-communication) multiplied
with a row distributed matrix especially if the indices are global indices. 
Each process just multiplies its local matrices.
\begin{align}
M = C\cdot R
\end{align}
This is not true the other way round. 
The result is then a row distributed matrix with global indices. 
From the global indices the gather map/matrix and the local
indices can be constructed.
We note here that we even don't need to construct the gather matrix
for $\nabla_\parallel^{fc}$, only the one for $\nabla_\parallel^c$ is
needed.
\section{Field aligned initialization} \label{sec:parallelc}

An important aspect of our simulations is a judicious initialization of the 
fields. We want structures to be field-aligned in the beginning of the simulation with
a possible modulation along the direction of the field line.
If a Gaussian shape is used, we call $\sigma_\parallel$ the extension in parallel
direction and write
\begin{align}
    f_0(R,Z,\varphi) = F(R,Z,\varphi) \exp\left( - \frac{(\varphi-\varphi_0)^2}{2\sigma_\parallel^2}\right),
    \label{eq:parallelInit}
\end{align}
where $F$ is a function that is invariant under the field line transformations
\begin{subequations}
\begin{align}
    \Tp F(\vec z) &= F( \Tp \vec z) \overset{!}{=} F(\vec z) \text{ (pull-back), } \\
    \Tm F(\vec z) &= F( \Tm \vec z) \overset{!}{=} F(\vec z) \text{ (push-forward). } 
\end{align}
\label{}
\end{subequations}
We can use these relations to construct aligned structures
by active transformations of some given field.
Our idea is to initialize a two-dimensional field $F(R,Z, \varphi_k)$ in a given plane $k$ and 
transform this field to all other planes using the recursive relations
\begin{subequations}
\begin{align}
    F( R, Z, \varphi_{k+1}) = \Tm F( R, Z, \varphi_{k+1}) = F(R^-, Z^-, \varphi_k), \\
    F( R, Z, \varphi_{k-1}) = \Tp F( R, Z, \varphi_{k-1}) = F(R^+, Z^+, \varphi_k),
\end{align}
    \label{eq:recursiveInit}
\end{subequations}
which is the statement that $F$ in the next plane equals the push-forward  
and $F$ in the previous plane equals the pull-back of $F$ in the current plane. 
Note here that Eq.~\eqref{eq:interpolation} applies for the required interpolation
procedures. 



%..................................................................
\bibliography{../references}
%..................................................................


\section{Numerical test programs}
The essential test programs for the parallel derivative are located in 
\code{
path/to/feltor/inc/geometries}.
\code{ ds\_t.cu} and \code{ ds\_mpit.cu} test the cylindrical grid for shared and distributed memory 
systems. \code{ ds\_curv\_t.cu} and \code{ ds\_curv\_mpit.cu} test the implementation
on a flux-aligned grid.
The magnetic field in FELTOR is given by
\begin{align}
  \vec B = \frac{R_0}{R}( I(\psi_p) \hat e_\varphi + \nabla\psi_p \times\hat e_\varphi)
\end{align}
This gives rise to magnetic field strength and components
\begin{align}
  B = \frac{R_0}{R} \sqrt{ I^2 + \left( \nabla\psi_p \right)^2} \\
  B^R = \frac{R_0}{R}\frac{\partial\psi_p}{\partial Z} \quad
  B^Z = -\frac{R_0}{R}\frac{\partial\psi_p}{\partial R}\quad 
  B^\varphi = \frac{R_0I}{R^2} \\
  \nabla \cdot\bhat = -\nabla_\parallel \ln B = -\frac{R_0}{RB^2} [B, \psi_p]  
  \label{}
\end{align}
where $[.,.]$ is the Poisson bracket.
\subsection{Cylindrical grid and circular flux surfaces}
A very simple non-trivial choice for the poloidal flux is
\begin{align}
  \psi_p = \frac{1}{2} \left( (R-R_0)^2 + Z^2 \right) \equiv \frac{1}{2} r^2
  \label{eq:circular}
\end{align}
for which 
\begin{align}
  \vec b^p &= \frac{1}{\sqrt{I^2 + r^2}} \begin{pmatrix} Z \\ -(R-R_0)\end{pmatrix} \\
  b^\varphi &= \frac{1}{\sqrt{I^2 + r^2}} I/R \\
  \nabla\cdot \bhat = \frac{Z}{R(I^2 + r^2} 
  \label{}
\end{align}
for the poloidal and toroidal parts of the magnetic unit vector. 
We choose $R_0 = 10$ and $I=20$ in order to keep the q-factor for the $r=1$ flux surface at $2$.
We set up a domain 
$R\in[R_0-1, R_0+1]$,
$Z\in[-1,1]$ and 
$\varphi \in [0,2\pi]$ and choose
\begin{align}
  f(R,Z,\varphi) = ((R-R_0)^2 + Z^2)\sin(\varphi)\\
  \bhat \cdot \nabla f= b^\varphi \cos(\varphi)
  \label{}
\end{align}
This is advantageous since the solution is correct even if we modify the $\bhat$ field
to be toroidal on the boundary of the domain in order to avoid boundary conditions. 
Also the function is parabolic, which means the dG polynomials of degree greater than $2$ 
should be exact. 
\subsection{Curvilinear grid}




\end{document}

